{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "batchsize = 16\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "learning_rate = 0.001\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "EEG Batch Shape: torch.Size([16, 1076])\n",
      "Label Batch Shape: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, data_path, labels_path):\n",
    "        self.data = np.load(data_path)\n",
    "        self.labels = np.load(labels_path)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get the EEG data and corresponding label\n",
    "        eeg = torch.tensor(self.data[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return eeg, label\n",
    "\n",
    "# Example usage\n",
    "train_dataset = EEGDataset(\"eeg_dataset/train_epochs.npy\", \"eeg_dataset/train_labels.npy\")\n",
    "val_dataset = EEGDataset(\"eeg_dataset/val_epochs.npy\", \"eeg_dataset/val_labels.npy\")\n",
    "test_dataset = EEGDataset(\"eeg_dataset/test_epochs.npy\", \"eeg_dataset/test_labels.npy\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batchsize, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batchsize, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batchsize, shuffle=False)\n",
    "\n",
    "print(len(train_loader))\n",
    "# Check one batch\n",
    "for eeg_batch, label_batch in train_loader:\n",
    "    print(\"EEG Batch Shape:\", eeg_batch.shape)  # (batch_size, 14, 640)\n",
    "    print(\"Label Batch Shape:\", label_batch.shape)  # (batch_size,)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.1)\n",
    "        self.dropout2 = nn.Dropout(p=0.1)\n",
    "        self.dropout3 = nn.Dropout(p=0.1)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.l1 = nn.Linear(input_size, 512)\n",
    "        self.l2 = nn.Linear(512, 256)\n",
    "        self.l3 = nn.Linear(256, 64)\n",
    "        self.l4 = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.l2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.l3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = self.l4(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 1.400624151583071, Validation Accuracy: 37.362637362637365%\n",
      "Epoch 2, Training Loss: 1.2909097406599257, Validation Accuracy: 50.54945054945055%\n",
      "Epoch 3, Training Loss: 1.1912864755701136, Validation Accuracy: 58.24175824175825%\n",
      "Epoch 4, Training Loss: 1.100425159489667, Validation Accuracy: 70.32967032967034%\n",
      "Epoch 5, Training Loss: 1.0383639909602977, Validation Accuracy: 73.62637362637363%\n",
      "Epoch 6, Training Loss: 0.9827218011573509, Validation Accuracy: 74.72527472527473%\n",
      "Epoch 7, Training Loss: 0.9305962213763485, Validation Accuracy: 79.12087912087912%\n",
      "Epoch 8, Training Loss: 0.8465247485372756, Validation Accuracy: 83.51648351648352%\n",
      "Epoch 9, Training Loss: 0.7862480900905751, Validation Accuracy: 81.31868131868131%\n",
      "Epoch 10, Training Loss: 0.7918329857013844, Validation Accuracy: 81.31868131868131%\n",
      "Epoch 11, Training Loss: 0.7476351879261158, Validation Accuracy: 86.81318681318682%\n",
      "Epoch 12, Training Loss: 0.7324011789427863, Validation Accuracy: 89.01098901098901%\n",
      "Epoch 13, Training Loss: 0.6928014004672015, Validation Accuracy: 87.91208791208791%\n",
      "Epoch 14, Training Loss: 0.6773000381611012, Validation Accuracy: 84.61538461538461%\n",
      "Epoch 15, Training Loss: 0.663265405981629, Validation Accuracy: 87.91208791208791%\n",
      "Epoch 16, Training Loss: 0.6582756395693179, Validation Accuracy: 85.71428571428571%\n",
      "Epoch 17, Training Loss: 0.6013134033591659, Validation Accuracy: 89.01098901098901%\n",
      "Epoch 18, Training Loss: 0.5995410791149846, Validation Accuracy: 89.01098901098901%\n",
      "Epoch 19, Training Loss: 0.6042694990281705, Validation Accuracy: 91.20879120879121%\n",
      "Epoch 20, Training Loss: 0.5564733820932882, Validation Accuracy: 90.10989010989012%\n",
      "Epoch 21, Training Loss: 0.524792406294081, Validation Accuracy: 93.4065934065934%\n",
      "Epoch 22, Training Loss: 0.514014971477014, Validation Accuracy: 91.20879120879121%\n",
      "Epoch 23, Training Loss: 0.5434323416815864, Validation Accuracy: 91.20879120879121%\n",
      "Epoch 24, Training Loss: 0.5072898379078618, Validation Accuracy: 91.20879120879121%\n",
      "Epoch 25, Training Loss: 0.49906948650324784, Validation Accuracy: 91.20879120879121%\n",
      "Epoch 26, Training Loss: 0.4837045404646132, Validation Accuracy: 91.20879120879121%\n",
      "Epoch 27, Training Loss: 0.4847622613112132, Validation Accuracy: 91.20879120879121%\n",
      "Epoch 28, Training Loss: 0.45033479178393326, Validation Accuracy: 92.3076923076923%\n",
      "Epoch 29, Training Loss: 0.43646060427029926, Validation Accuracy: 91.20879120879121%\n",
      "Epoch 30, Training Loss: 0.4549594389067756, Validation Accuracy: 92.3076923076923%\n",
      "Epoch 31, Training Loss: 0.4218008451991611, Validation Accuracy: 92.3076923076923%\n",
      "Epoch 32, Training Loss: 0.432497215491754, Validation Accuracy: 90.10989010989012%\n",
      "Epoch 33, Training Loss: 0.4343068246488218, Validation Accuracy: 89.01098901098901%\n",
      "Epoch 34, Training Loss: 0.37764348255263436, Validation Accuracy: 93.4065934065934%\n",
      "Epoch 35, Training Loss: 0.35669997665617204, Validation Accuracy: 91.20879120879121%\n",
      "Epoch 36, Training Loss: 0.4045453286833233, Validation Accuracy: 92.3076923076923%\n",
      "Epoch 37, Training Loss: 0.37137093643347424, Validation Accuracy: 92.3076923076923%\n",
      "Epoch 38, Training Loss: 0.35508100909215434, Validation Accuracy: 95.6043956043956%\n",
      "Epoch 39, Training Loss: 0.3443983660803901, Validation Accuracy: 94.5054945054945%\n",
      "Epoch 40, Training Loss: 0.3312637960469281, Validation Accuracy: 95.6043956043956%\n",
      "Epoch 41, Training Loss: 0.38314506135605, Validation Accuracy: 93.4065934065934%\n",
      "Epoch 42, Training Loss: 0.33602099727701257, Validation Accuracy: 92.3076923076923%\n",
      "Epoch 43, Training Loss: 0.33377122823838834, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 44, Training Loss: 0.32774373999348394, Validation Accuracy: 93.4065934065934%\n",
      "Epoch 45, Training Loss: 0.29590154301237176, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 46, Training Loss: 0.3235285160718141, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 47, Training Loss: 0.3053535830091547, Validation Accuracy: 95.6043956043956%\n",
      "Epoch 48, Training Loss: 0.29486375164102624, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 49, Training Loss: 0.27165061621754255, Validation Accuracy: 94.5054945054945%\n",
      "Epoch 50, Training Loss: 0.3068808686954004, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 51, Training Loss: 0.27971142916767683, Validation Accuracy: 95.6043956043956%\n",
      "Epoch 52, Training Loss: 0.28698599504099953, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 53, Training Loss: 0.2803962230682373, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 54, Training Loss: 0.2691662283959212, Validation Accuracy: 92.3076923076923%\n",
      "Epoch 55, Training Loss: 0.26590504469694914, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 56, Training Loss: 0.2549094276295768, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 57, Training Loss: 0.2440165755925355, Validation Accuracy: 93.4065934065934%\n",
      "Epoch 58, Training Loss: 0.23568008453757675, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 59, Training Loss: 0.24790034194787344, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 60, Training Loss: 0.27083620042712603, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 61, Training Loss: 0.23106994811031553, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 62, Training Loss: 0.2343814555141661, Validation Accuracy: 95.6043956043956%\n",
      "Epoch 63, Training Loss: 0.25903509115731277, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 64, Training Loss: 0.20872879690594143, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 65, Training Loss: 0.2342594376316777, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 66, Training Loss: 0.2224462021280218, Validation Accuracy: 94.5054945054945%\n",
      "Epoch 67, Training Loss: 0.23122547649674946, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 68, Training Loss: 0.19326643921710826, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 69, Training Loss: 0.20578271923241792, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 70, Training Loss: 0.22439174133318443, Validation Accuracy: 100.0%\n",
      "Epoch 71, Training Loss: 0.1955197505928852, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 72, Training Loss: 0.2201097028123008, Validation Accuracy: 95.6043956043956%\n",
      "Epoch 73, Training Loss: 0.2208055575136785, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 74, Training Loss: 0.18155031927205897, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 75, Training Loss: 0.19888265817253678, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 76, Training Loss: 0.1935718462423042, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 77, Training Loss: 0.1753539346434452, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 78, Training Loss: 0.1723628408379025, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 79, Training Loss: 0.19885293311542934, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 80, Training Loss: 0.18465598148328285, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 81, Training Loss: 0.20856780724392998, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 82, Training Loss: 0.19041053150539045, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 83, Training Loss: 0.20915659792997218, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 84, Training Loss: 0.22039294022100944, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 85, Training Loss: 0.17827062446762015, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 86, Training Loss: 0.19506492493329225, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 87, Training Loss: 0.14883576968201884, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 88, Training Loss: 0.16044653041495216, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 89, Training Loss: 0.14524297057478516, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 90, Training Loss: 0.1447218938006295, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 91, Training Loss: 0.15938474155134624, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 92, Training Loss: 0.16689991426688652, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 93, Training Loss: 0.14275073094500434, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 94, Training Loss: 0.1558393066128095, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 95, Training Loss: 0.13377420093726228, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 96, Training Loss: 0.13641115871292572, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 97, Training Loss: 0.15268605671547078, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 98, Training Loss: 0.17426248805390465, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 99, Training Loss: 0.15375420175216817, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 100, Training Loss: 0.1296449248437528, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 101, Training Loss: 0.19045645357282073, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 102, Training Loss: 0.13033780538373524, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 103, Training Loss: 0.12822345106138122, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 104, Training Loss: 0.13663436775958096, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 105, Training Loss: 0.14145738493513177, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 106, Training Loss: 0.1640653720608464, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 107, Training Loss: 0.12261932908936783, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 108, Training Loss: 0.11370152648952273, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 109, Training Loss: 0.13548125712959855, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 110, Training Loss: 0.12042811775097141, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 111, Training Loss: 0.11490414567567685, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 112, Training Loss: 0.1292129730184873, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 113, Training Loss: 0.15623363259213943, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 114, Training Loss: 0.14780086803215522, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 115, Training Loss: 0.11027306097525137, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 116, Training Loss: 0.12512665931825284, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 117, Training Loss: 0.10337764493845127, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 118, Training Loss: 0.11926703472380284, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 119, Training Loss: 0.10879167652240505, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 120, Training Loss: 0.13769433330054637, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 121, Training Loss: 0.13254826074397122, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 122, Training Loss: 0.11389906207720439, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 123, Training Loss: 0.11464435151881641, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 124, Training Loss: 0.11940065053878007, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 125, Training Loss: 0.13859626595620755, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 126, Training Loss: 0.08668627203614623, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 127, Training Loss: 0.12810010752744144, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 128, Training Loss: 0.0952151663325451, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 129, Training Loss: 0.17545312767227492, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 130, Training Loss: 0.09132265009813839, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 131, Training Loss: 0.13736697727883304, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 132, Training Loss: 0.07561474307267754, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 133, Training Loss: 0.11762430298107641, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 134, Training Loss: 0.10608595140554287, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 135, Training Loss: 0.11037271718184154, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 136, Training Loss: 0.0922571751806471, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 137, Training Loss: 0.09189908937723548, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 138, Training Loss: 0.09237296561951991, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 139, Training Loss: 0.071538586307455, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 140, Training Loss: 0.11590300348621828, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 141, Training Loss: 0.10618427920120733, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 142, Training Loss: 0.10607527265394176, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 143, Training Loss: 0.10092720610124094, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 144, Training Loss: 0.07535366645013844, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 145, Training Loss: 0.07645878402723207, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 146, Training Loss: 0.07903726026415825, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 147, Training Loss: 0.07638772107936719, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 148, Training Loss: 0.07718158623686543, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 149, Training Loss: 0.07080338729752435, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 150, Training Loss: 0.08767825875569273, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 151, Training Loss: 0.07235923519840946, Validation Accuracy: 100.0%\n",
      "Epoch 152, Training Loss: 0.06068534134990639, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 153, Training Loss: 0.08542392044155686, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 154, Training Loss: 0.07665087248164194, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 155, Training Loss: 0.06994460385154795, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 156, Training Loss: 0.08181204212208588, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 157, Training Loss: 0.12143210507929325, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 158, Training Loss: 0.09909283045541357, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 159, Training Loss: 0.1280404466583773, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 160, Training Loss: 0.0733054056763649, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 161, Training Loss: 0.0799799390413143, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 162, Training Loss: 0.13678096296886602, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 163, Training Loss: 0.07813586287752346, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 164, Training Loss: 0.09365639759710541, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 165, Training Loss: 0.14154832072004123, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 166, Training Loss: 0.08041402414717057, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 167, Training Loss: 0.11363058302689481, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 168, Training Loss: 0.0726820494013804, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 169, Training Loss: 0.06465877537374143, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 170, Training Loss: 0.07358378834194607, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 171, Training Loss: 0.06319410636745117, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 172, Training Loss: 0.08402917265064186, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 173, Training Loss: 0.07019176906733601, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 174, Training Loss: 0.07056783001731944, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 175, Training Loss: 0.11067900710083821, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 176, Training Loss: 0.10263034501285465, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 177, Training Loss: 0.05935210589733389, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 178, Training Loss: 0.08728719544079569, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 179, Training Loss: 0.08191772667622124, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 180, Training Loss: 0.06949970215834954, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 181, Training Loss: 0.0943245976059525, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 182, Training Loss: 0.06896423265613892, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 183, Training Loss: 0.07356955421467622, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 184, Training Loss: 0.10388317704200745, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 185, Training Loss: 0.04269885837479874, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 186, Training Loss: 0.08104751493643832, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 187, Training Loss: 0.15026856924372692, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 188, Training Loss: 0.09556722661687268, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 189, Training Loss: 0.05983473319146368, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 190, Training Loss: 0.048509260846508875, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 191, Training Loss: 0.06411051860562077, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 192, Training Loss: 0.08122557443049219, Validation Accuracy: 96.7032967032967%\n",
      "Epoch 193, Training Loss: 0.09178733736000678, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 194, Training Loss: 0.055344430798733676, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 195, Training Loss: 0.07806338645793774, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 196, Training Loss: 0.08220959151232685, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 197, Training Loss: 0.08519811590236646, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 198, Training Loss: 0.07042342341608471, Validation Accuracy: 97.8021978021978%\n",
      "Epoch 199, Training Loss: 0.07733225898334274, Validation Accuracy: 98.9010989010989%\n",
      "Epoch 200, Training Loss: 0.0900551791958235, Validation Accuracy: 97.8021978021978%\n"
     ]
    }
   ],
   "source": [
    "model = MLP(1076, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for eeg, labels in train_loader:\n",
    "        \n",
    "        eeg = eeg.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(eeg)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for eeg, labels in val_loader:\n",
    "            eeg = eeg.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            output = model(eeg)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            val_accuracy += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "    val_accuracy /= len(val_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}, Training Loss: {running_loss/len(train_loader)}, Validation Accuracy: {val_accuracy * 100}%')\n",
    "\n",
    "    if val_accuracy > best_acc:\n",
    "        best_acc = val_accuracy\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 92.22222222222223\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_state_dict(best_model_wts)\n",
    "# test\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for eeg, labels in test_loader:\n",
    "        eeg = eeg.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(eeg)\n",
    "        \n",
    "        # # print(outputs)\n",
    "        # print(torch.max(outputs, 1))\n",
    "        # print(\"ACC\")\n",
    "        # print(labels)\n",
    "        # break\n",
    "        \n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions==labels).sum().item()\n",
    "        \n",
    "    acc = 100 * (n_correct/n_samples)\n",
    "    print(f'accuracy = {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
